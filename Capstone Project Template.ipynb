{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pyspark in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pyspark) (0.10.9)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "#!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import lower, col\n",
    "from pprint import pprint\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import pyarrow.parquet as pq\n",
    "import re\n",
    "import os, sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "pd.set_option('display.width',170, 'display.max_rows',200, 'display.max_columns',900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "##### The immigration data comes form US National Tourism and Trade Office. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data source\n",
    "air_data = \"airport-codes_csv.csv\"\n",
    "city_data=\"us-cities-demographics.csv\"\n",
    "temp_file=\"weather/GlobalLandTemperaturesByCity.csv\"\n",
    "sas=\"I94_SAS_Labels_Descriptions.SAS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the imgration data\n",
    "df_img = pq.ParquetDataset('sas_data').read_pandas().to_pandas(split_blocks=True, self_destruct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  depdate  i94bir  i94visa  count  dtadfile visapost occup entdepa entdepd entdepu matflag  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None      NaN    37.0      2.0    1.0      None     None  None       T    None       U    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL      NaN    25.0      3.0    1.0  20130811      SEO  None       G    None       Y    None   \n",
       "\n",
       "   biryear   dtaddto gender insnum airline        admnum  fltno visatype  \n",
       "0   1979.0  10282016   None   None    None  1.897628e+09   None       B2  \n",
       "1   1991.0       D/S      M   None    None  3.736796e+09  00296       F1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cicid</th>\n      <th>i94yr</th>\n      <th>i94mon</th>\n      <th>i94cit</th>\n      <th>i94res</th>\n      <th>i94port</th>\n      <th>arrdate</th>\n      <th>i94mode</th>\n      <th>i94addr</th>\n      <th>depdate</th>\n      <th>i94bir</th>\n      <th>i94visa</th>\n      <th>count</th>\n      <th>dtadfile</th>\n      <th>visapost</th>\n      <th>occup</th>\n      <th>entdepa</th>\n      <th>entdepd</th>\n      <th>entdepu</th>\n      <th>matflag</th>\n      <th>biryear</th>\n      <th>dtaddto</th>\n      <th>gender</th>\n      <th>insnum</th>\n      <th>airline</th>\n      <th>admnum</th>\n      <th>fltno</th>\n      <th>visatype</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.0</td>\n      <td>2016.0</td>\n      <td>4.0</td>\n      <td>692.0</td>\n      <td>692.0</td>\n      <td>XXX</td>\n      <td>20573.0</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>37.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>T</td>\n      <td>None</td>\n      <td>U</td>\n      <td>None</td>\n      <td>1979.0</td>\n      <td>10282016</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1.897628e+09</td>\n      <td>None</td>\n      <td>B2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.0</td>\n      <td>2016.0</td>\n      <td>4.0</td>\n      <td>254.0</td>\n      <td>276.0</td>\n      <td>ATL</td>\n      <td>20551.0</td>\n      <td>1.0</td>\n      <td>AL</td>\n      <td>NaN</td>\n      <td>25.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>20130811</td>\n      <td>SEO</td>\n      <td>None</td>\n      <td>G</td>\n      <td>None</td>\n      <td>Y</td>\n      <td>None</td>\n      <td>1991.0</td>\n      <td>D/S</td>\n      <td>M</td>\n      <td>None</td>\n      <td>None</td>\n      <td>3.736796e+09</td>\n      <td>00296</td>\n      <td>F1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# Explor the Data\n",
    "df_img.head(2)"
   ]
  },
  {
   "source": [
    "#### Data Dictionary that we are interesting in:\n",
    "##### Immigration Data\n",
    "- cicid - float64 - ID that is unique, identify the dataset\n",
    "- i94yr - float64 - 4 digit year\n",
    "- i94cit - float64 - 3 digit code of immigrant born country\n",
    "- i94res - float64 - 3 digit code of immigrant country of residence\n",
    "- arrdate - float64 - Arrival date in the USA\n",
    "- i94port = 3 character code of destination USA city\n",
    "- i94mode - float64 - Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)\n",
    "- biryear - float64 - 4 digit year of birth\n",
    "- i94visa - float64 - Visa codes modified into: (B1, E2 = Business; B2 = Pleasure; F1 = Student, WB, WT= Three months visit, others = the rest)\n",
    "- gender - \n",
    "- fltno - object - Flight number of Airline used to arrive in U.S.\n",
    "- visatype - object - Class of admission legally admitting the non-immigrant to temporarily stay in U.S. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "cicid        0.000000\n",
       "i94yr        0.000000\n",
       "i94cit       0.000000\n",
       "i94port      0.000000\n",
       "i94res       0.000000\n",
       "arrdate      0.000000\n",
       "i94mode      0.007719\n",
       "biryear      0.025902\n",
       "i94visa      0.000000\n",
       "gender      13.379429\n",
       "fltno        0.631364\n",
       "visatype     0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# select the data and show missing value\n",
    "new_df_img=df_img[['cicid', 'i94yr', 'i94cit', 'i94port','i94res', 'arrdate', 'i94mode', 'biryear','i94visa', 'gender', 'fltno', 'visatype']] \n",
    "(new_df_img.isna().sum() /len(new_df_img)) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   i94cit i94port  i94res  arrdate  i94mode  biryear  i94visa gender\n",
       "0   692.0     XXX   692.0  20573.0      NaN   1979.0      2.0   None\n",
       "1   254.0     ATL   276.0  20551.0      1.0   1991.0      3.0      M"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>i94cit</th>\n      <th>i94port</th>\n      <th>i94res</th>\n      <th>arrdate</th>\n      <th>i94mode</th>\n      <th>biryear</th>\n      <th>i94visa</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>692.0</td>\n      <td>XXX</td>\n      <td>692.0</td>\n      <td>20573.0</td>\n      <td>NaN</td>\n      <td>1979.0</td>\n      <td>2.0</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>254.0</td>\n      <td>ATL</td>\n      <td>276.0</td>\n      <td>20551.0</td>\n      <td>1.0</td>\n      <td>1991.0</td>\n      <td>3.0</td>\n      <td>M</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "new_df_img[['i94cit', 'i94port','i94res', 'arrdate', 'i94mode', 'biryear','i94visa', 'gender']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3 Months Visa    1592042\n",
       "Pleasure         1117897\n",
       "Business          231793\n",
       "Others            115565\n",
       "Student            39016\n",
       "Name: visatype, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Cleaning: replace visatype values into 4 catogories: (B1, E2 = Business; B2 = Pleasure; F1 = Student, WB, WT= Three months visit, others = the rest)\n",
    "new_df_img['visatype']= new_df_img['visatype'].replace(['B1', 'E2'], 'Business')\n",
    "new_df_img['visatype']= new_df_img['visatype'].replace('B2', 'Pleasure')\n",
    "new_df_img['visatype']= new_df_img['visatype'].replace('F1', 'Student')\n",
    "new_df_img['visatype']= new_df_img['visatype'].replace(['WB','WT'], '3 Months Visa')\n",
    "new_df_img['visatype']= new_df_img['visatype'].replace(['WB','WT'], '3 Months Visa')\n",
    "new_df_img['visatype']= new_df_img['visatype'].replace(['GMT','CP', 'E1','I', 'F2','M1', 'I1', 'GMB', 'M2', 'SBP', 'CPL'], 'Others')\n",
    "\n",
    "new_df_img.visatype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "M    1377224\n",
       "F    1302743\n",
       "X       1610\n",
       "U        467\n",
       "Name: gender, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "new_df_img.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3096313 entries, 0 to 3096312\nData columns (total 12 columns):\n #   Column    Dtype  \n---  ------    -----  \n 0   cicid     float64\n 1   i94yr     float64\n 2   i94cit    float64\n 3   i94port   object \n 4   i94res    float64\n 5   arrdate   float64\n 6   i94mode   float64\n 7   biryear   float64\n 8   i94visa   float64\n 9   gender    object \n 10  fltno     object \n 11  visatype  object \ndtypes: float64(8), object(4)\nmemory usage: 283.5+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df_img.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I94YR : 4 digit year\nI94MON : Numeric month\nI94CIT & I94RES : This format shows all the valid and invalid codes for processing\nI94PORT : This format shows all the valid and invalid codes for processing\nI94MODE : There are missing values as well as not reported (9)\nI94BIR : Age of Respondent in Years\nCOUNT : Used for summary statistics\nDTADFILE : Character Date Field - Date added to I-94 Files - CIC does not use\nVISAPOST : Department of State where where Visa was issued - CIC does not use\nOCCUP : Occupation that will be performed in U.S. - CIC does not use\nENTDEPA : Arrival Flag - admitted or paroled into the U.S. - CIC does not use\nENTDEPD : Departure Flag - Departed, lost I-94 or is deceased - CIC does not use\nENTDEPU : Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use\nMATFLAG : Match flag - Match of arrival and departure records\nBIRYEAR : 4 digit year of birth\nDTADDTO : Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use\nGENDER : Non-immigrant sex\nINSNUM : INS number\nAIRLINE : Airline used to arrive in U.S.\nADMNUM : Admission Number\nFLTNO : Flight number of Airline used to arrive in U.S.\nVISATYPE : Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n"
     ]
    }
   ],
   "source": [
    "# Collect data from SAS file(port_code, port_city, port_state) \n",
    "with open(sas) as f:\n",
    "    lines = f.readlines()    \n",
    "\n",
    "comments = [line for line in lines if '/*' in line and '*/\\n' in line]\n",
    "regexp = re.compile(r'^/\\*\\s+(?P<code>.+?)\\s+-\\s+(?P<description>.+)\\s+\\*/$')\n",
    "matches = [regexp.match(c) for c in comments]\n",
    "\n",
    "for m in matches:\n",
    "    print(m.group(\"code\"), \":\", m.group('description'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  port_code                 port_city port_state\n",
       "0       ALC                     ALCAN         AK\n",
       "1       ANC                 ANCHORAGE         AK\n",
       "2       BAR  BAKER AAF - BAKER ISLAND         AK\n",
       "3       DAC             DALTONS CACHE         AK\n",
       "4       PIZ    DEW STATION PT LAY DEW         AK"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>port_code</th>\n      <th>port_city</th>\n      <th>port_state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ALC</td>\n      <td>ALCAN</td>\n      <td>AK</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ANC</td>\n      <td>ANCHORAGE</td>\n      <td>AK</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BAR</td>\n      <td>BAKER AAF - BAKER ISLAND</td>\n      <td>AK</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DAC</td>\n      <td>DALTONS CACHE</td>\n      <td>AK</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PIZ</td>\n      <td>DEW STATION PT LAY DEW</td>\n      <td>AK</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Get port locations from SAS text file\n",
    "with open(\"./I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip() for x in content]\n",
    "ports = content[302:962]\n",
    "splitted_ports = [port.split(\"=\") for port in ports]\n",
    "port_codes = [x[0].replace(\"'\",\"\").strip() for x in splitted_ports]\n",
    "port_locations = [x[1].replace(\"'\",\"\").strip() for x in splitted_ports]\n",
    "port_cities = [x.split(\",\")[0] for x in port_locations]\n",
    "port_states = [x.split(\",\")[-1] for x in port_locations]\n",
    "df_port_locations = pd.DataFrame({\"port_code\" : port_codes, \"port_city\": port_cities, \"port_state\": port_states})\n",
    "df_port_locations.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Springfield     9545\n",
       "Worcester       8359\n",
       "León            7469\n",
       "Rongcheng       6526\n",
       "Manchester      6478\n",
       "                ... \n",
       "Machala         1591\n",
       "Trujillo        1584\n",
       "Chimbote        1584\n",
       "Chiclayo        1584\n",
       "Port Moresby    1581\n",
       "Name: City, Length: 3448, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#read weather file\n",
    "temp_df=pd.read_csv(temp_file)\n",
    "temp_df.tail(1)\n",
    "temp_df['City'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "df = spark.createDataFrame(new_df_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):  \n",
    "     temp = df.filter(df.i94port.isin(list(valid_ports.keys())))\n",
    "     return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df=clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+------+------+-------+------+-------+-------+-------+-------+------+-----+--------+\n|cicid| i94yr|i94cit|i94port|i94res|arrdate|i94mode|biryear|i94visa|gender|fltno|visatype|\n+-----+------+------+-------+------+-------+-------+-------+-------+------+-----+--------+\n|  6.0|2016.0| 692.0|    XXX| 692.0|20573.0|    NaN| 1979.0|    2.0|  null| null|Pleasure|\n|  7.0|2016.0| 254.0|    ATL| 276.0|20551.0|    1.0| 1991.0|    3.0|     M|00296| Student|\n| 15.0|2016.0| 101.0|    WAS| 101.0|20545.0|    1.0| 1961.0|    2.0|     M|   93|Pleasure|\n| 16.0|2016.0| 101.0|    NYC| 101.0|20545.0|    1.0| 1988.0|    2.0|  null|00199|Pleasure|\n| 17.0|2016.0| 101.0|    NYC| 101.0|20545.0|    1.0| 2012.0|    2.0|  null|00199|Pleasure|\n| 18.0|2016.0| 101.0|    NYC| 101.0|20545.0|    1.0| 1959.0|    1.0|  null|00602|Business|\n| 19.0|2016.0| 101.0|    NYC| 101.0|20545.0|    1.0| 1953.0|    2.0|  null|00602|Pleasure|\n| 20.0|2016.0| 101.0|    NYC| 101.0|20545.0|    1.0| 1959.0|    2.0|  null|00602|Pleasure|\n| 21.0|2016.0| 101.0|    NYC| 101.0|20545.0|    1.0| 1970.0|    2.0|  null|00602|Pleasure|\n| 22.0|2016.0| 101.0|    NYC| 101.0|20545.0|    1.0| 1968.0|    1.0|  null|00608|Business|\n| 23.0|2016.0| 101.0|    NYC| 101.0|20545.0|    1.0| 1964.0|    2.0|  null|00001|Pleasure|\n| 24.0|2016.0| 101.0|    TOR| 101.0|20545.0|    1.0| 1983.0|    2.0|  null|03348|Pleasure|\n| 27.0|2016.0| 101.0|    BOS| 101.0|20545.0|    1.0| 1958.0|    1.0|     M|00422|Business|\n| 28.0|2016.0| 101.0|    ATL| 101.0|20545.0|    1.0| 1960.0|    1.0|     F|00422|Business|\n| 29.0|2016.0| 101.0|    ATL| 101.0|20545.0|    1.0| 1954.0|    2.0|     M|00614|Pleasure|\n| 30.0|2016.0| 101.0|    ATL| 101.0|20545.0|    1.0| 1967.0|    2.0|     M|00089|Pleasure|\n| 31.0|2016.0| 101.0|    ATL| 101.0|20545.0|    1.0| 1973.0|    2.0|     M|00089|Pleasure|\n| 33.0|2016.0| 101.0|    HOU| 101.0|20545.0|    1.0| 1963.0|    2.0|     F|00033|Pleasure|\n| 34.0|2016.0| 101.0|    NYC| 101.0|20545.0|    1.0| 1968.0|    2.0|     M|00602|Pleasure|\n| 35.0|2016.0| 101.0|    NYC| 101.0|20545.0|    1.0| 1942.0|    2.0|     F|    1|Pleasure|\n+-----+------+------+-------+------+-------+-------+-------+-------+------+-----+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "img_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.createDataFrame(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data\n",
    "\n",
    "def clean_data(temp_df, img_df):\n",
    "    temp_df = temp_df.filter(temp_df.AverageTemperature != 'NaN')\n",
    "    temp_df = temp_df.dropDuplicates(['City', 'Country'])\n",
    "    temp_df = temp_df.withColumn(\"i94port\", img_df.select('i94port'))\n",
    "    return temp_df.filter(temp_df.i94port != 'null')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = clean_data(df,img_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conceptual Data Model\n",
    "#### imigration dim:\n",
    "new_df_img.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dim_temperature\n",
    "temp_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/temperature.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary views of the immigration and temperature data\n",
    "new_df_img.createOrReplaceTempView(\"new_df_img\")\n",
    "df_temp.createOrReplaceTempView(\"temp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fact table by joining the immigration and temperature views\n",
    "fact_table = spark.sql('''\n",
    "SELECT new_df_img.i94yr as year,\n",
    "       new_df_img.i94mon as month,\n",
    "       new_df_img.i94cit as city,\n",
    "       new_df_img.i94port as i94port,\n",
    "       new_df_img.arrdate as arrival_date,\n",
    "       new_df_img.depdate as departure_date,\n",
    "       new_df_img.i94visa as reason,\n",
    "       df_temp.AverageTemperature as temperature,\n",
    "       df_temp.Latitude as latitude,\n",
    "       df_temp.Longitude as longitude\n",
    "FROM new_df_img\n",
    "JOIN df_temp ON (new_df_img.i94port = df_temp.i94port)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write fact table to parquet files partitioned by i94port\n",
    "fact_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/fact.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "def quality_check(df, description):\n",
    "    result = df.count()\n",
    "    \n",
    "    if result == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(description))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(description, result))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data quality check\n",
    "quality_check(new_df_img, \"immigration table\")\n",
    "quality_check(df_temp, \"temperature table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}